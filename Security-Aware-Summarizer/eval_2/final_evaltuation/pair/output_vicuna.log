nohup: ignoring input
Using device: cuda
Processing dataset:   0%|          | 0/59 [00:00<?, ?row/s]Processing dataset: 100%|██████████| 59/59 [00:00<00:00, 30449.60row/s]
2024-10-17 17:36:20.890786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-10-17 17:36:20.902943: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-10-17 17:36:20.906703: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-10-17 17:36:20.918999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-10-17 17:36:21.531618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /home/shagoto/.cache/huggingface/token
Login successful
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:  33%|███▎      | 1/3 [27:15<54:30, 1635.43s/it]Downloading shards:  67%|██████▋   | 2/3 [56:54<28:40, 1720.10s/it]Error while downloading from https://cdn-lfs.hf.co/repos/8d/0f/8d0f2419520bb2a42aac5a182f3e9ae84d9c5210220f1c85c36197edcd55cb28/b4bd8cf2ab7e7bf22aaaf9b35ec5d41602d83f5a97bb82e17662ffe0a20ab215?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model-00003-of-00003.bin%3B+filename%3D%22pytorch_model-00003-of-00003.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1729474399&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTQ3NDM5OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy84ZC8wZi84ZDBmMjQxOTUyMGJiMmE0MmFhYzVhMTgyZjNlOWFlODRkOWM1MjEwMjIwZjFjODVjMzYxOTdlZGNkNTVjYjI4L2I0YmQ4Y2YyYWI3ZTdiZjIyYWFhZjliMzVlYzVkNDE2MDJkODNmNWE5N2JiODJlMTc2NjJmZmUwYTIwYWIyMTU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=KXUFOo7RlMGa0dThjrqC7HgUPy3zKZ3Sm67Gjc5xWH8yICh6ACMUoBIqGHDuOmnPeQI5ud6LdxAWGOc33NbZYTiZZvp3pDq3pATtozMkEY-M58TMrIoEaoJFYClMKDkAa6zrT04VdlwSXM0yanTTBwZUrIf35NAE7HPDoU0ZcjWafnUfxVOWagmoE1IOoNlTcTTljbl27ajlaHptb2g-nOtYuKogNEWfL5u-w8FAKkCnDcyEjBwBtWHEGZicqvnlqW4BdZasNOc0-oyIr8JMVB0XnhlxmYSJLH-M6y%7ENYlBXuXquQR77x4E72djtD%7EdfznAcUvh6ujiSfvME2vsObA__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.
Trying to resume download...
Downloading shards: 100%|██████████| 3/3 [1:11:42<00:00, 1340.05s/it]Downloading shards: 100%|██████████| 3/3 [1:11:42<00:00, 1434.20s/it]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:24<00:10, 10.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:25<00:00,  6.25s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:25<00:00,  8.50s/it]
/home/shagoto/miniconda3/envs/shagoto_venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/shagoto/miniconda3/envs/shagoto_venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/shagoto/miniconda3/envs/shagoto_venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/shagoto/miniconda3/envs/shagoto_venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Generating responses:   0%|          | 0/59 [00:00<?, ?it/s]/home/shagoto/miniconda3/envs/shagoto_venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/shagoto/miniconda3/envs/shagoto_venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:623: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Generating responses:   2%|▏         | 1/59 [00:09<08:57,  9.27s/it]Generating responses:   3%|▎         | 2/59 [00:18<08:30,  8.96s/it]Generating responses:   5%|▌         | 3/59 [00:26<08:16,  8.86s/it]Generating responses:   7%|▋         | 4/59 [00:35<08:04,  8.80s/it]Generating responses:   8%|▊         | 5/59 [00:44<07:55,  8.80s/it]Generating responses:  10%|█         | 6/59 [00:52<07:44,  8.77s/it]Generating responses:  12%|█▏        | 7/59 [01:01<07:35,  8.75s/it]Generating responses:  14%|█▎        | 8/59 [01:10<07:26,  8.75s/it]Generating responses:  15%|█▌        | 9/59 [01:19<07:16,  8.74s/it]Generating responses:  17%|█▋        | 10/59 [01:27<07:08,  8.74s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Generating responses:  19%|█▊        | 11/59 [01:36<06:59,  8.73s/it]Generating responses:  20%|██        | 12/59 [01:45<06:50,  8.73s/it]Generating responses:  22%|██▏       | 13/59 [01:54<06:42,  8.74s/it]Generating responses:  24%|██▎       | 14/59 [02:02<06:33,  8.74s/it]Generating responses:  25%|██▌       | 15/59 [02:11<06:24,  8.75s/it]Generating responses:  27%|██▋       | 16/59 [02:20<06:16,  8.75s/it]Generating responses:  29%|██▉       | 17/59 [02:29<06:07,  8.74s/it]Generating responses:  31%|███       | 18/59 [02:33<05:10,  7.57s/it]Generating responses:  32%|███▏      | 19/59 [02:40<04:54,  7.36s/it]Generating responses:  34%|███▍      | 20/59 [02:49<05:02,  7.76s/it]Generating responses:  36%|███▌      | 21/59 [02:58<05:06,  8.06s/it]Generating responses:  37%|███▋      | 22/59 [03:06<05:05,  8.26s/it]Generating responses:  39%|███▉      | 23/59 [03:15<05:02,  8.40s/it]Generating responses:  41%|████      | 24/59 [03:18<04:00,  6.88s/it]Generating responses:  42%|████▏     | 25/59 [03:27<04:12,  7.43s/it]Generating responses:  44%|████▍     | 26/59 [03:36<04:18,  7.84s/it]Generating responses:  46%|████▌     | 27/59 [03:45<04:19,  8.12s/it]Generating responses:  47%|████▋     | 28/59 [03:54<04:17,  8.30s/it]Generating responses:  49%|████▉     | 29/59 [04:02<04:13,  8.44s/it]Generating responses:  51%|█████     | 30/59 [04:11<04:07,  8.53s/it]Generating responses:  53%|█████▎    | 31/59 [04:16<03:25,  7.35s/it]Generating responses:  54%|█████▍    | 32/59 [04:24<03:29,  7.78s/it]Generating responses:  56%|█████▌    | 33/59 [04:33<03:29,  8.07s/it]Generating responses:  58%|█████▊    | 34/59 [04:42<03:27,  8.28s/it]Generating responses:  59%|█████▉    | 35/59 [04:51<03:22,  8.43s/it]Generating responses:  61%|██████    | 36/59 [04:59<03:16,  8.52s/it]Generating responses:  63%|██████▎   | 37/59 [05:08<03:09,  8.59s/it]Generating responses:  64%|██████▍   | 38/59 [05:17<03:01,  8.64s/it]Generating responses:  66%|██████▌   | 39/59 [05:26<02:53,  8.68s/it]Generating responses:  68%|██████▊   | 40/59 [05:35<02:45,  8.71s/it]Generating responses:  69%|██████▉   | 41/59 [05:43<02:37,  8.73s/it]Generating responses:  71%|███████   | 42/59 [05:46<01:59,  7.04s/it]Generating responses:  73%|███████▎  | 43/59 [05:55<02:01,  7.58s/it]Generating responses:  75%|███████▍  | 44/59 [06:04<01:59,  7.94s/it]Generating responses:  76%|███████▋  | 45/59 [06:13<01:54,  8.19s/it]Generating responses:  78%|███████▊  | 46/59 [06:22<01:48,  8.36s/it]Generating responses:  80%|███████▉  | 47/59 [06:30<01:41,  8.48s/it]Generating responses:  81%|████████▏ | 48/59 [06:39<01:34,  8.56s/it]Generating responses:  83%|████████▎ | 49/59 [06:46<01:19,  7.96s/it]Generating responses:  85%|████████▍ | 50/59 [06:54<01:13,  8.20s/it]Generating responses:  86%|████████▋ | 51/59 [07:03<01:06,  8.37s/it]Generating responses:  88%|████████▊ | 52/59 [07:12<00:59,  8.49s/it]Generating responses:  90%|████████▉ | 53/59 [07:21<00:51,  8.57s/it]Generating responses:  92%|█████████▏| 54/59 [07:29<00:43,  8.63s/it]Generating responses:  93%|█████████▎| 55/59 [07:38<00:34,  8.67s/it]Generating responses:  95%|█████████▍| 56/59 [07:47<00:26,  8.71s/it]Generating responses:  97%|█████████▋| 57/59 [07:56<00:17,  8.72s/it]Generating responses:  98%|█████████▊| 58/59 [08:04<00:08,  8.73s/it]Generating responses: 100%|██████████| 59/59 [08:13<00:00,  8.72s/it]Generating responses: 100%|██████████| 59/59 [08:13<00:00,  8.37s/it]
